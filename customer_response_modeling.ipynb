{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Goal of the project**","metadata":{}},{"cell_type":"markdown","source":"The predictive response models used to help identify customers in marketing can also be used to help outbound sales teams improve their call conversion rate by targeting the best people or companies to call. Whether we’re sending emails or using catalogue marketing, or calling customers by phone, the principles are identical - we’re aiming to increase profit by generating the maximum amount of revenue from the minimum amount of effort and cost.\n\nThe aim of this project will be to identify the customers most likely to respond when called, using only features known about the customers, to help the outbound sales team increase their call conversion rate.","metadata":{}},{"cell_type":"markdown","source":"**Load the packages**","metadata":{}},{"cell_type":"code","source":"# Importing libraries\nimport pandas as pd\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2022-08-10T12:32:23.607233Z","iopub.execute_input":"2022-08-10T12:32:23.607831Z","iopub.status.idle":"2022-08-10T12:32:23.615470Z","shell.execute_reply.started":"2022-08-10T12:32:23.607777Z","shell.execute_reply":"2022-08-10T12:32:23.613777Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"**Load the data**","metadata":{}},{"cell_type":"markdown","source":"For this project I’m using the [Marketing Customer Value Dataset](https://www.kaggle.com/datasets/pankajjsh06/ibm-watson-marketing-customer-value-data) provided by IBM Watson Analytics. The statistics are about whether the customer has accepted or rejected the offer extended to them.","metadata":{}},{"cell_type":"code","source":"# Load dataset\ndf = pd.read_csv('../input/ibm-watson-marketing-customer-value-data/WA_Fn-UseC_-Marketing-Customer-Value-Analysis.csv').iloc[: , 1:]","metadata":{"execution":{"iopub.status.busy":"2022-08-10T12:32:23.829395Z","iopub.execute_input":"2022-08-10T12:32:23.830213Z","iopub.status.idle":"2022-08-10T12:32:23.889692Z","shell.execute_reply.started":"2022-08-10T12:32:23.830166Z","shell.execute_reply":"2022-08-10T12:32:23.888211Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Rename Pandas columns to lower case\ndf.columns = df.columns.str.lower()","metadata":{"execution":{"iopub.status.busy":"2022-08-10T12:32:24.147174Z","iopub.execute_input":"2022-08-10T12:32:24.147839Z","iopub.status.idle":"2022-08-10T12:32:24.154409Z","shell.execute_reply.started":"2022-08-10T12:32:24.147790Z","shell.execute_reply":"2022-08-10T12:32:24.152918Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df = df.applymap(lambda s: s.lower() if type(s) == str else s)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T12:32:24.238459Z","iopub.execute_input":"2022-08-10T12:32:24.239639Z","iopub.status.idle":"2022-08-10T12:32:24.355779Z","shell.execute_reply.started":"2022-08-10T12:32:24.239593Z","shell.execute_reply":"2022-08-10T12:32:24.354554Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Examine the data\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-10T12:32:24.357665Z","iopub.execute_input":"2022-08-10T12:32:24.358102Z","iopub.status.idle":"2022-08-10T12:32:24.392157Z","shell.execute_reply.started":"2022-08-10T12:32:24.358064Z","shell.execute_reply":"2022-08-10T12:32:24.390560Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"        state  customer lifetime value response  coverage education  \\\n0  washington              2763.519279       no     basic  bachelor   \n1     arizona              6979.535903       no  extended  bachelor   \n2      nevada             12887.431650       no   premium  bachelor   \n3  california              7645.861827       no     basic  bachelor   \n4  washington              2813.692575       no     basic  bachelor   \n\n  effective to date employmentstatus gender  income location code  ...  \\\n0           2/24/11         employed      f   56274      suburban  ...   \n1           1/31/11       unemployed      f       0      suburban  ...   \n2           2/19/11         employed      f   48767      suburban  ...   \n3           1/20/11       unemployed      m       0      suburban  ...   \n4            2/3/11         employed      m   43836         rural  ...   \n\n  months since policy inception  number of open complaints  \\\n0                             5                          0   \n1                            42                          0   \n2                            38                          0   \n3                            65                          0   \n4                            44                          0   \n\n   number of policies     policy type        policy  renew offer type  \\\n0                   1  corporate auto  corporate l3            offer1   \n1                   8   personal auto   personal l3            offer3   \n2                   2   personal auto   personal l3            offer1   \n3                   7  corporate auto  corporate l2            offer1   \n4                   1   personal auto   personal l1            offer1   \n\n  sales channel total claim amount  vehicle class vehicle size  \n0         agent         384.811147   two-door car      medsize  \n1         agent        1131.464935  four-door car      medsize  \n2         agent         566.472247   two-door car      medsize  \n3   call center         529.881344            suv      medsize  \n4         agent         138.130879  four-door car      medsize  \n\n[5 rows x 23 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>state</th>\n      <th>customer lifetime value</th>\n      <th>response</th>\n      <th>coverage</th>\n      <th>education</th>\n      <th>effective to date</th>\n      <th>employmentstatus</th>\n      <th>gender</th>\n      <th>income</th>\n      <th>location code</th>\n      <th>...</th>\n      <th>months since policy inception</th>\n      <th>number of open complaints</th>\n      <th>number of policies</th>\n      <th>policy type</th>\n      <th>policy</th>\n      <th>renew offer type</th>\n      <th>sales channel</th>\n      <th>total claim amount</th>\n      <th>vehicle class</th>\n      <th>vehicle size</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>washington</td>\n      <td>2763.519279</td>\n      <td>no</td>\n      <td>basic</td>\n      <td>bachelor</td>\n      <td>2/24/11</td>\n      <td>employed</td>\n      <td>f</td>\n      <td>56274</td>\n      <td>suburban</td>\n      <td>...</td>\n      <td>5</td>\n      <td>0</td>\n      <td>1</td>\n      <td>corporate auto</td>\n      <td>corporate l3</td>\n      <td>offer1</td>\n      <td>agent</td>\n      <td>384.811147</td>\n      <td>two-door car</td>\n      <td>medsize</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>arizona</td>\n      <td>6979.535903</td>\n      <td>no</td>\n      <td>extended</td>\n      <td>bachelor</td>\n      <td>1/31/11</td>\n      <td>unemployed</td>\n      <td>f</td>\n      <td>0</td>\n      <td>suburban</td>\n      <td>...</td>\n      <td>42</td>\n      <td>0</td>\n      <td>8</td>\n      <td>personal auto</td>\n      <td>personal l3</td>\n      <td>offer3</td>\n      <td>agent</td>\n      <td>1131.464935</td>\n      <td>four-door car</td>\n      <td>medsize</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>nevada</td>\n      <td>12887.431650</td>\n      <td>no</td>\n      <td>premium</td>\n      <td>bachelor</td>\n      <td>2/19/11</td>\n      <td>employed</td>\n      <td>f</td>\n      <td>48767</td>\n      <td>suburban</td>\n      <td>...</td>\n      <td>38</td>\n      <td>0</td>\n      <td>2</td>\n      <td>personal auto</td>\n      <td>personal l3</td>\n      <td>offer1</td>\n      <td>agent</td>\n      <td>566.472247</td>\n      <td>two-door car</td>\n      <td>medsize</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>california</td>\n      <td>7645.861827</td>\n      <td>no</td>\n      <td>basic</td>\n      <td>bachelor</td>\n      <td>1/20/11</td>\n      <td>unemployed</td>\n      <td>m</td>\n      <td>0</td>\n      <td>suburban</td>\n      <td>...</td>\n      <td>65</td>\n      <td>0</td>\n      <td>7</td>\n      <td>corporate auto</td>\n      <td>corporate l2</td>\n      <td>offer1</td>\n      <td>call center</td>\n      <td>529.881344</td>\n      <td>suv</td>\n      <td>medsize</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>washington</td>\n      <td>2813.692575</td>\n      <td>no</td>\n      <td>basic</td>\n      <td>bachelor</td>\n      <td>2/3/11</td>\n      <td>employed</td>\n      <td>m</td>\n      <td>43836</td>\n      <td>rural</td>\n      <td>...</td>\n      <td>44</td>\n      <td>0</td>\n      <td>1</td>\n      <td>personal auto</td>\n      <td>personal l1</td>\n      <td>offer1</td>\n      <td>agent</td>\n      <td>138.130879</td>\n      <td>four-door car</td>\n      <td>medsize</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 23 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Overview of all variables, their datatypes\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2022-08-10T12:32:24.444312Z","iopub.execute_input":"2022-08-10T12:32:24.445453Z","iopub.status.idle":"2022-08-10T12:32:24.475114Z","shell.execute_reply.started":"2022-08-10T12:32:24.445381Z","shell.execute_reply":"2022-08-10T12:32:24.473323Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 9134 entries, 0 to 9133\nData columns (total 23 columns):\n #   Column                         Non-Null Count  Dtype  \n---  ------                         --------------  -----  \n 0   state                          9134 non-null   object \n 1   customer lifetime value        9134 non-null   float64\n 2   response                       9134 non-null   object \n 3   coverage                       9134 non-null   object \n 4   education                      9134 non-null   object \n 5   effective to date              9134 non-null   object \n 6   employmentstatus               9134 non-null   object \n 7   gender                         9134 non-null   object \n 8   income                         9134 non-null   int64  \n 9   location code                  9134 non-null   object \n 10  marital status                 9134 non-null   object \n 11  monthly premium auto           9134 non-null   int64  \n 12  months since last claim        9134 non-null   int64  \n 13  months since policy inception  9134 non-null   int64  \n 14  number of open complaints      9134 non-null   int64  \n 15  number of policies             9134 non-null   int64  \n 16  policy type                    9134 non-null   object \n 17  policy                         9134 non-null   object \n 18  renew offer type               9134 non-null   object \n 19  sales channel                  9134 non-null   object \n 20  total claim amount             9134 non-null   float64\n 21  vehicle class                  9134 non-null   object \n 22  vehicle size                   9134 non-null   object \ndtypes: float64(2), int64(6), object(15)\nmemory usage: 1.6+ MB\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Define the target variable**","metadata":{}},{"cell_type":"markdown","source":"At the moment, the response column contains a boolean yes or no value, but we need to “binarise” this to turn it into a numeric value the model can use. A simple replace( ) is one of several ways to do this.","metadata":{}},{"cell_type":"code","source":"df['response'] = df['response'].replace(('yes', 'no'), (1, 0))","metadata":{"execution":{"iopub.status.busy":"2022-08-10T12:32:24.498734Z","iopub.execute_input":"2022-08-10T12:32:24.499257Z","iopub.status.idle":"2022-08-10T12:32:24.515679Z","shell.execute_reply.started":"2022-08-10T12:32:24.499217Z","shell.execute_reply":"2022-08-10T12:32:24.513979Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"As we’ll see from examining the value_counts( ) of the target variable column, this dataset is imbalanced.","metadata":{}},{"cell_type":"code","source":"df['response'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-08-10T12:32:24.546972Z","iopub.execute_input":"2022-08-10T12:32:24.548135Z","iopub.status.idle":"2022-08-10T12:32:24.558771Z","shell.execute_reply.started":"2022-08-10T12:32:24.548068Z","shell.execute_reply":"2022-08-10T12:32:24.557156Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"0    7826\n1    1308\nName: response, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"**Changing a date string to a datetime**","metadata":{}},{"cell_type":"code","source":"df['effective to date'] = pd.to_datetime(df['effective to date'])","metadata":{"execution":{"iopub.status.busy":"2022-08-10T12:32:24.600077Z","iopub.execute_input":"2022-08-10T12:32:24.600575Z","iopub.status.idle":"2022-08-10T12:32:24.621238Z","shell.execute_reply.started":"2022-08-10T12:32:24.600537Z","shell.execute_reply":"2022-08-10T12:32:24.619621Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"**Engineer datetime feature**","metadata":{}},{"cell_type":"markdown","source":"Basically we can break apart the date and get the week.","metadata":{}},{"cell_type":"code","source":"df['week'] = df['effective to date'].dt.strftime('%W').astype(int)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T12:32:24.687032Z","iopub.execute_input":"2022-08-10T12:32:24.688248Z","iopub.status.idle":"2022-08-10T12:32:24.746962Z","shell.execute_reply.started":"2022-08-10T12:32:24.688201Z","shell.execute_reply":"2022-08-10T12:32:24.745686Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"df = df.drop('effective to date', axis = 1)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T12:32:24.757577Z","iopub.execute_input":"2022-08-10T12:32:24.758081Z","iopub.status.idle":"2022-08-10T12:32:24.771078Z","shell.execute_reply.started":"2022-08-10T12:32:24.758040Z","shell.execute_reply":"2022-08-10T12:32:24.769971Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"**Check for missing values**","metadata":{}},{"cell_type":"markdown","source":"Before moving on, we’ll check to see if there are any null values to impute. However, the data were all fine, so there was nothing to do.","metadata":{}},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-08-10T12:32:24.806717Z","iopub.execute_input":"2022-08-10T12:32:24.808500Z","iopub.status.idle":"2022-08-10T12:32:24.825269Z","shell.execute_reply.started":"2022-08-10T12:32:24.808440Z","shell.execute_reply":"2022-08-10T12:32:24.824070Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"state                            0\ncustomer lifetime value          0\nresponse                         0\ncoverage                         0\neducation                        0\nemploymentstatus                 0\ngender                           0\nincome                           0\nlocation code                    0\nmarital status                   0\nmonthly premium auto             0\nmonths since last claim          0\nmonths since policy inception    0\nnumber of open complaints        0\nnumber of policies               0\npolicy type                      0\npolicy                           0\nrenew offer type                 0\nsales channel                    0\ntotal claim amount               0\nvehicle class                    0\nvehicle size                     0\nweek                             0\ndtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"**Define X and y**","metadata":{}},{"cell_type":"code","source":"X = df.drop('response', axis = 1)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T12:32:24.829204Z","iopub.execute_input":"2022-08-10T12:32:24.830557Z","iopub.status.idle":"2022-08-10T12:32:24.839484Z","shell.execute_reply.started":"2022-08-10T12:32:24.830518Z","shell.execute_reply":"2022-08-10T12:32:24.838204Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"y = df['response']","metadata":{"execution":{"iopub.status.busy":"2022-08-10T12:32:24.883584Z","iopub.execute_input":"2022-08-10T12:32:24.884192Z","iopub.status.idle":"2022-08-10T12:32:24.891091Z","shell.execute_reply.started":"2022-08-10T12:32:24.884147Z","shell.execute_reply":"2022-08-10T12:32:24.889564Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"**Create the training and test datasets**","metadata":{}},{"cell_type":"markdown","source":"To divide X and y into the train and test datasets we need to train the model we will use the train_test_split( ) function from scikit-learn. We’ll assign 30% of the data to the test groups using the argument test_size = 0.3, and we’ll use the stratify = y option to ensure the target variable is present in the test and train data in equal proportions. The random_state = 42 argument means we get reproducible results each time we run the code, rather than a random mix, which may give us different results.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2022-08-10T12:32:25.051984Z","iopub.execute_input":"2022-08-10T12:32:25.054307Z","iopub.status.idle":"2022-08-10T12:32:25.615610Z","shell.execute_reply.started":"2022-08-10T12:32:25.054241Z","shell.execute_reply":"2022-08-10T12:32:25.614222Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Isolate X and y variables, and perform train-test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42, stratify = y)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T12:32:25.618314Z","iopub.execute_input":"2022-08-10T12:32:25.618688Z","iopub.status.idle":"2022-08-10T12:32:25.640458Z","shell.execute_reply.started":"2022-08-10T12:32:25.618655Z","shell.execute_reply":"2022-08-10T12:32:25.639346Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"**Create a pipeline**","metadata":{}},{"cell_type":"markdown","source":"First, we’re extracting the numeric columns from X and returning a list, then we’re doing the same with the categorical data columns. For the categorical data, we’re applying the OneHotEncoder( ) to ensure everything is numeric. These settings get passed to the ColumnTransformer( ).\n\nNext, we’re using the pipeline from imblearn, which is specifically designed for working with imbalanced datasets like this one. The pipeline first runs our preprocessor we just created, then uses the SMOTE–ENN Technique to handle the class imbalance. Finally, we use the RobustScaler( ) to put our data on a consistent scale, then pass in the model and return a bundled_pipeline.","metadata":{}},{"cell_type":"code","source":"import time\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\n\nfrom imblearn.pipeline import Pipeline as imbpipeline\nfrom imblearn.combine import SMOTEENN\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import roc_auc_score","metadata":{"execution":{"iopub.status.busy":"2022-08-10T12:32:25.642277Z","iopub.execute_input":"2022-08-10T12:32:25.642894Z","iopub.status.idle":"2022-08-10T12:32:25.743335Z","shell.execute_reply.started":"2022-08-10T12:32:25.642828Z","shell.execute_reply":"2022-08-10T12:32:25.741371Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def get_pipeline(X, model):\n\n    numeric_columns = list(X.select_dtypes(exclude = ['object']).columns.values.tolist())    \n    categorical_columns = list(X.select_dtypes(include = ['object']).columns.values.tolist())\n    categorical_pipeline = OneHotEncoder(sparse = False, handle_unknown = 'ignore')\n    \n    preprocessor = ColumnTransformer(transformers = [('numeric', 'passthrough', numeric_columns),\n                                                     ('categorical', categorical_pipeline, categorical_columns)], remainder = 'passthrough')\n\n    bundled_pipeline = imbpipeline(steps = [('preprocessor', preprocessor),\n                                            ('smote', SMOTEENN(random_state = 42)),\n                                            ('scaler', RobustScaler()),\n                                            ('model', model)])\n    \n    return bundled_pipeline","metadata":{"execution":{"iopub.status.busy":"2022-08-10T12:32:25.746921Z","iopub.execute_input":"2022-08-10T12:32:25.747646Z","iopub.status.idle":"2022-08-10T12:32:25.756953Z","shell.execute_reply.started":"2022-08-10T12:32:25.747606Z","shell.execute_reply":"2022-08-10T12:32:25.755687Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"**Select the best model for the job**","metadata":{}},{"cell_type":"markdown","source":"What we’re doing here is defining a big dictionary of classifier models, and then looping through them, running the data through our pipeline above, and using cross validation and predicted values to assess which model is best.","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBClassifier, XGBRFClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\nfrom sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, HistGradientBoostingClassifier\nfrom catboost import CatBoostClassifier","metadata":{"execution":{"iopub.status.busy":"2022-08-10T12:32:37.365538Z","iopub.execute_input":"2022-08-10T12:32:37.366300Z","iopub.status.idle":"2022-08-10T12:32:38.225937Z","shell.execute_reply.started":"2022-08-10T12:32:37.366234Z","shell.execute_reply":"2022-08-10T12:32:38.224547Z"},"trusted":true},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style type='text/css'>\n.datatable table.frame { margin-bottom: 0; }\n.datatable table.frame thead { border-bottom: none; }\n.datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n.datatable .bool    { background: #DDDD99; }\n.datatable .object  { background: #565656; }\n.datatable .int     { background: #5D9E5D; }\n.datatable .float   { background: #4040CC; }\n.datatable .str     { background: #CC4040; }\n.datatable .time    { background: #40CC40; }\n.datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n.datatable .frame tbody td { text-align: left; }\n.datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n.datatable th:nth-child(2) { padding-left: 12px; }\n.datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n.datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n.datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n.datatable .sp {  opacity: 0.25;}\n.datatable .footer { font-size: 9px; }\n.datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n</style>\n"},"metadata":{}}]},{"cell_type":"code","source":"def select_model(X, y, pipeline = None):\n\n  classifiers = {}\n  classifiers.update({'XGBClassifier': XGBClassifier(random_state = 42)})\n  classifiers.update({'XGBRFClassifier': XGBRFClassifier(random_state = 42)})\n  classifiers.update({'LGBMClassifier': LGBMClassifier(random_state = 42)})\n  classifiers.update({'DecisionTreeClassifier': DecisionTreeClassifier(random_state = 42)})\n  classifiers.update({'RandomForestClassifier': RandomForestClassifier(random_state = 42)})\n  classifiers.update({'ExtraTreesClassifier': ExtraTreesClassifier(random_state = 42)})\n  classifiers.update({'GradientBoostingClassifier': GradientBoostingClassifier(random_state = 42)})    \n  classifiers.update({'BaggingClassifier': BaggingClassifier(random_state = 42)})\n  classifiers.update({'AdaBoostClassifier': AdaBoostClassifier(random_state = 42)})\n  classifiers.update({'HistGradientBoostingClassifier': HistGradientBoostingClassifier(random_state = 42)})\n  classifiers.update({'CatBoostClassifier': CatBoostClassifier(silent = True, random_state = 42)})\n\n  df_models = pd.DataFrame(columns = ['model', 'run_time', 'roc_auc_cv', 'roc_auc'])\n\n  for key in classifiers:\n\n      print('*', key)\n\n      start_time = time.time()\n      \n      pipeline = get_pipeline(X_train, classifiers[key])\n\n      cv = cross_val_score(pipeline, X, y, cv = 5, scoring = 'roc_auc', n_jobs = -1)\n\n      pipeline.fit(X_train, y_train)\n      y_pred = pipeline.predict(X_test)\n\n      row = {'model': key,\n             'run_time': format(round((time.time() - start_time) / 60, 2)),\n             'roc_auc_cv': cv.mean(),\n             'roc_auc': roc_auc_score(y_test, y_pred)}\n\n      df_models = df_models.append(row, ignore_index = True)\n\n  df_models = df_models.sort_values(by = 'roc_auc', ascending = False)\n      \n  return df_models","metadata":{"execution":{"iopub.status.busy":"2022-08-10T12:32:38.227784Z","iopub.execute_input":"2022-08-10T12:32:38.228168Z","iopub.status.idle":"2022-08-10T12:32:38.243177Z","shell.execute_reply.started":"2022-08-10T12:32:38.228135Z","shell.execute_reply":"2022-08-10T12:32:38.241464Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"models = select_model(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T12:32:38.245130Z","iopub.execute_input":"2022-08-10T12:32:38.245500Z","iopub.status.idle":"2022-08-10T12:36:35.822897Z","shell.execute_reply.started":"2022-08-10T12:32:38.245467Z","shell.execute_reply":"2022-08-10T12:36:35.821068Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"* XGBClassifier\n* XGBRFClassifier\n* LGBMClassifier\n* DecisionTreeClassifier\n* RandomForestClassifier\n* ExtraTreesClassifier\n* GradientBoostingClassifier\n* BaggingClassifier\n* AdaBoostClassifier\n* HistGradientBoostingClassifier\n* CatBoostClassifier\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Running the select_model( ) function on our training data takes a minute or so. The best independent model was CatBoostClassifier. ","metadata":{}},{"cell_type":"code","source":"models.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T12:36:35.825355Z","iopub.execute_input":"2022-08-10T12:36:35.825744Z","iopub.status.idle":"2022-08-10T12:36:35.847803Z","shell.execute_reply.started":"2022-08-10T12:36:35.825711Z","shell.execute_reply":"2022-08-10T12:36:35.846217Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"                             model run_time  roc_auc_cv   roc_auc\n10              CatBoostClassifier     1.59    0.979062  0.975166\n0                    XGBClassifier     0.39    0.975731  0.970492\n2                   LGBMClassifier     0.21    0.972976  0.921726\n5             ExtraTreesClassifier     0.21    0.974983  0.914742\n9   HistGradientBoostingClassifier     0.22    0.971707  0.897335\n7                BaggingClassifier     0.18    0.933886  0.837303\n3           DecisionTreeClassifier     0.13    0.820193  0.836284\n4           RandomForestClassifier     0.22    0.954916  0.803842\n1                  XGBRFClassifier     0.29    0.810252  0.700859\n6       GradientBoostingClassifier     0.33    0.845458  0.636908","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>run_time</th>\n      <th>roc_auc_cv</th>\n      <th>roc_auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10</th>\n      <td>CatBoostClassifier</td>\n      <td>1.59</td>\n      <td>0.979062</td>\n      <td>0.975166</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>XGBClassifier</td>\n      <td>0.39</td>\n      <td>0.975731</td>\n      <td>0.970492</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>LGBMClassifier</td>\n      <td>0.21</td>\n      <td>0.972976</td>\n      <td>0.921726</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>ExtraTreesClassifier</td>\n      <td>0.21</td>\n      <td>0.974983</td>\n      <td>0.914742</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>HistGradientBoostingClassifier</td>\n      <td>0.22</td>\n      <td>0.971707</td>\n      <td>0.897335</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>BaggingClassifier</td>\n      <td>0.18</td>\n      <td>0.933886</td>\n      <td>0.837303</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>DecisionTreeClassifier</td>\n      <td>0.13</td>\n      <td>0.820193</td>\n      <td>0.836284</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>RandomForestClassifier</td>\n      <td>0.22</td>\n      <td>0.954916</td>\n      <td>0.803842</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>XGBRFClassifier</td>\n      <td>0.29</td>\n      <td>0.810252</td>\n      <td>0.700859</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>GradientBoostingClassifier</td>\n      <td>0.33</td>\n      <td>0.845458</td>\n      <td>0.636908</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Finally, we can take our best model and fit the data on this. To do this step, we’ll first define our stacked model, then we’ll pass its configuration to get_pipeline( ) with our training data. Then, we’ll fit( ) the training data and use predict( ) to return our predictions from the newly trained model.","metadata":{}},{"cell_type":"code","source":"selected_model = CatBoostClassifier(silent = True, random_state = 42)\nbundled_pipeline = get_pipeline(X_train, selected_model)\nbundled_pipeline.fit(X_train, y_train)\ny_pred = bundled_pipeline.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T12:36:35.851921Z","iopub.execute_input":"2022-08-10T12:36:35.852344Z","iopub.status.idle":"2022-08-10T12:36:52.169564Z","shell.execute_reply.started":"2022-08-10T12:36:35.852311Z","shell.execute_reply":"2022-08-10T12:36:52.168168Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"**Assess the performance of the model**","metadata":{}},{"cell_type":"markdown","source":"To examine how well the model performed in a little more detail we can make use of the classification_report( ) function. The classification report shows us the precision, recall, and F1 score for our predictions.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report","metadata":{"execution":{"iopub.status.busy":"2022-08-10T12:36:52.171351Z","iopub.execute_input":"2022-08-10T12:36:52.171767Z","iopub.status.idle":"2022-08-10T12:36:52.178436Z","shell.execute_reply.started":"2022-08-10T12:36:52.171730Z","shell.execute_reply":"2022-08-10T12:36:52.176783Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-08-10T12:37:11.311761Z","iopub.execute_input":"2022-08-10T12:37:11.312289Z","iopub.status.idle":"2022-08-10T12:37:11.330443Z","shell.execute_reply.started":"2022-08-10T12:37:11.312246Z","shell.execute_reply":"2022-08-10T12:37:11.328671Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.99      0.99      0.99      2348\n           1       0.93      0.96      0.95       393\n\n    accuracy                           0.98      2741\n   macro avg       0.96      0.98      0.97      2741\nweighted avg       0.98      0.98      0.98      2741\n\n","output_type":"stream"}]}]}